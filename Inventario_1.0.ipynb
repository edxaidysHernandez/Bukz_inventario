{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c2800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4da8ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"sales_2023-06-01_2023-11-30 (3).csv\") # archivo ventas\n",
    "inventario_original_1 = pd.read_excel(\"inventario0412.xlsx\") # archivo inventario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d85218",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventario_original_1 = inventario_original_1.loc[:, ~inventario_original_1.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde60c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventario_original = inventario_original_1.loc[~inventario_original_1['Vendor'].isin(['Bukz USA', 'Bukz España'])].copy()\n",
    "inventario_original = inventario_original.loc[inventario_original['Type'].isin(['Libro', 'Libros', 'Libros impresos'])]\n",
    "inventario_original['ID'] = inventario_original['ID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7068f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el promedio de ventas basado en el número de meses de creación\n",
    "def compute_sales_based_on_creation(row):\n",
    "    total_sales = row[months].sum()\n",
    "    return total_sales / row['meses de creación']\n",
    "\n",
    "# Detecta si un producto ha tenido ventas de manera intermitente (i.e., ha tenido ventas, luego no ventas, y luego ventas nuevamente)\n",
    "def is_intermittent(s):\n",
    "    had_sales = False\n",
    "    had_no_sales = False\n",
    "    for sale in s:\n",
    "        if sale > 0:\n",
    "            if had_no_sales:\n",
    "                return True\n",
    "            had_sales = True\n",
    "        else:\n",
    "            if had_sales:\n",
    "                had_no_sales = True\n",
    "    return False\n",
    "\n",
    "# Calcula el promedio de ventas para aquellos registros que tienen ventas intermitentes\n",
    "def compute_average(s):\n",
    "    months_with_sales = len(s[s > 0])\n",
    "    if months_with_sales == 0:\n",
    "        return 0\n",
    "    return s.sum() / months_with_sales\n",
    "\n",
    "\n",
    "# Calcula el promedio de ventas solo para los meses en los que hubo ventas\n",
    "def compute_average_sales(row):\n",
    "    months_with_sales = row[months].loc[row[months] > 0]\n",
    "    return months_with_sales.mean()\n",
    "\n",
    "# Calcula el promedio total de ventas considerando todos los meses\n",
    "def compute_total_average(row, months):\n",
    "    return row[months].sum() / len(months)\n",
    "\n",
    "# Calcula el promedio de ventas de los últimos 6 meses\n",
    "def compute_six_month_average(row):\n",
    "    return row[months].mean()\n",
    "\n",
    "# Asigna un valor sugerido y una descripción de caso a los registros del dataframe basado en una condición\n",
    "def set_suggested_and_case(df, condition, suggested_value, case_description):\n",
    "    df.loc[condition, 'sugerido'] = suggested_value\n",
    "    df.loc[condition, 'tipo_caso'] = case_description\n",
    "    return df\n",
    "\n",
    "# Asigna un valor sugerido para libros antiguos con ventas bajas\n",
    "def set_suggested_for_old_books(df):\n",
    "    condition = (df['meses de creación'] >= 5) & (df['Total'].isin([1, 2]))\n",
    "    return set_suggested_and_case(df, condition, 1, \"Mas de 5 meses de creación y 2 o menos libros vendidos\")\n",
    "\n",
    "# Asigna un valor sugerido basado en el promedio de ventas para aquellos registros que han vendido durante 5 o 6 meses\n",
    "def set_suggested_for_months_with_sales(df):\n",
    "    condition = df['MonthsWithSales'].isin([5, 6])\n",
    "    suggested_value = (df['Total'] / df['MonthsWithSales']).mul(1).round(0).astype(float)\n",
    "    return set_suggested_and_case(df, condition, suggested_value, \"5 o 6 meses de venta\")\n",
    "\n",
    "# Asigna un valor sugerido para productos creados recientemente\n",
    "def set_suggested_for_recent_creation(df):\n",
    "    condition = (df['meses de creación'] <= 4) & (df['sugerido'].isna())\n",
    "    suggested_value = df.apply(compute_sales_based_on_creation, axis=1).round(0).fillna(0).astype(int)\n",
    "    return set_suggested_and_case(df, condition, suggested_value, \"Creado hace menos de 4 meses\")\n",
    "\n",
    "# Asigna un valor sugerido para productos con ventas intermitentes\n",
    "def set_suggested_for_intermittent_sales(df, month_columns):\n",
    "    df['intermittent'] = df[month_columns].apply(is_intermittent, axis=1)\n",
    "    condition = df['intermittent'] & df['sugerido'].isna()\n",
    "    suggested_value = df[month_columns].apply(compute_average, axis=1).mul(1).round(0)\n",
    "    return set_suggested_and_case(df, condition, suggested_value, \"Ventas intermitentes (posibles agotados)\")\n",
    "\n",
    "# Asigna un valor sugerido para productos que actualmente no tienen inventario\n",
    "def set_suggested_for_no_inventory(df, inv_sede):\n",
    "    condition = (df[inv_sede] == 0) & (df['August'] == 0) & df['sugerido'].isna()\n",
    "    suggested_value = df.apply(compute_average_sales, axis=1).round(0)\n",
    "    return set_suggested_and_case(df, condition, suggested_value, \"Productos sin inventario en bodega actualmente\")\n",
    "\n",
    "# Asigna un valor sugerido para productos de reciente creación con ventas bajas\n",
    "def set_suggested_for_recent_creation_with_low_sales(df):\n",
    "    condition = (df['meses de creación'] < 5) & df['Total'].isin([1, 2, 3, 4]) & df['sugerido'].isna()\n",
    "    return set_suggested_and_case(df, condition, 1, \"Meses de creación menor a 5 y promedio de ventas 0,8 o menos, 1 predeterminado\")\n",
    "\n",
    "# Asigna un valor sugerido basado en el promedio de ventas de los últimos 6 meses\n",
    "def set_suggested_for_average_sales(df, months):\n",
    "    condition = (df['meses de creación'] > 4) & df['MonthsWithSales'].isin([3, 4]) & df['sugerido'].isna()\n",
    "    suggested_value = df.apply(lambda row: compute_total_average(row, months), axis=1).round(0)\n",
    "    return set_suggested_and_case(df, condition, suggested_value, \"Promedio de ventas de 6 meses\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5959d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_values(row):\n",
    "    caso = row['tipo_caso']\n",
    "    sugerido = row['sugerido']\n",
    "    total = row['Total']\n",
    "\n",
    "    # Por defecto, mantendremos sugerido_2 y meses de inventario como NaN\n",
    "    sugerido_2 = np.nan\n",
    "    meses_de_inventario = np.nan\n",
    "\n",
    "    if caso == \"5 o 6 meses de venta\":\n",
    "        sugerido_2 = sugerido * 4 if sugerido >= 5 else sugerido * 2\n",
    "        meses_de_inventario = 4 if sugerido >= 5 else 2\n",
    "\n",
    "    elif caso == \"Creado hace menos de 4 meses\":\n",
    "        sugerido_2 = sugerido * 3 if sugerido >= 5 else sugerido * 2\n",
    "        meses_de_inventario = 3 if sugerido >= 5 else 2\n",
    "\n",
    "    elif caso == \"Mas de 5 meses de creación y 2 o menos libros vendidos\":\n",
    "        sugerido_2 = sugerido\n",
    "        meses_de_inventario = \"\"\n",
    "\n",
    "    elif caso == \"Meses de creación menor a 5 y promedio de ventas 0,8 o menos, 1 predeterminado\":\n",
    "        sugerido_2 = sugerido * 2\n",
    "        meses_de_inventario = 2\n",
    "\n",
    "    elif caso == \"Productos sin inventario en bodega actualmente\":\n",
    "        sugerido_2 = sugerido * 2 if sugerido < 5 else sugerido * 3\n",
    "        meses_de_inventario = 2 if sugerido < 5 else 3\n",
    "\n",
    "    elif caso == \"Promedio de ventas de 6 meses\":\n",
    "        sugerido_2 = sugerido * 2 if total >= 5 else sugerido\n",
    "        meses_de_inventario = 2 if total >= 5 else \"\"\n",
    "\n",
    "    elif caso == \"Ventas intermitentes (posibles agotados)\":\n",
    "        sugerido_2 = sugerido * 2\n",
    "        meses_de_inventario = 2\n",
    "\n",
    "    return pd.Series([sugerido_2, meses_de_inventario], index=['sugerido_2', 'meses de inventario'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cfcd1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completo Bukz Tesoro\n",
      "Completo Bukz Las Lomas\n",
      "Completo Bukz Mattelsa\n"
     ]
    }
   ],
   "source": [
    "sedes = ['Bukz Tesoro', 'Bukz Las Lomas', 'Bukz Mattelsa' ] \n",
    "\n",
    "resultados = {}  # Diccionario vacío para almacenar los DataFrames\n",
    "\n",
    "for sede in sedes:\n",
    "    inventario2 = inventario_original.copy()\n",
    "    inv_sede = \"Inventory Available: \" + sede\n",
    "\n",
    "    months = [ 'June', 'July', 'August', 'September','October', 'November']\n",
    "\n",
    "    # Filtrar las filas que cumplan con el criterio\n",
    "    df = df1.loc[~df1['product_vendor'].isin(['Bukz USA', 'Bukz España'])]\n",
    "    df = df.loc[df['product_type'].isin(['Libro', 'Libros', 'Libros impresos'])]\n",
    "    df[\"net_quantity\"] = df[\"net_quantity\"].apply(lambda x: abs(x))\n",
    "    df.loc[df['net_quantity'] > 3, 'net_quantity'] = 1\n",
    "    df['pos_location_name'] = df['pos_location_name'].replace('Libreria Provenza', 'Bukz Las Lomas')\n",
    "    df = df.loc[df['api_client_title'].isin(['Point of Sale'])]\n",
    "    df = df.loc[df['pos_location_name'].isin([sede])]\n",
    "\n",
    "        # Convertir la columna 'day' a formato de fecha\n",
    "    df['day'] = pd.to_datetime(df['day'], format='%Y-%m-%d')\n",
    "\n",
    "    # Agrupar por día y product_id y sumar las cantidades\n",
    "    df = df.groupby(['day', 'product_id', 'variant_sku']).sum().reset_index()\n",
    "    \n",
    "    def categorize_quantity(qty):\n",
    "        if qty <= 2:\n",
    "            return qty\n",
    "        elif 3 <= qty < 7:\n",
    "            return 1\n",
    "        elif 7 <= qty <= 10:\n",
    "            return 2\n",
    "        elif qty >= 11:\n",
    "            return 3\n",
    "\n",
    "    df['net_quantity'] = df['net_quantity'].apply(categorize_quantity)\n",
    "\n",
    "    # Agregar una columna 'month_name' con los nombres de los meses\n",
    "    df['month_name'] = df['day'].dt.strftime('%B')\n",
    "\n",
    "    # Pivotear el DataFrame para tener los nombres de los meses como columnas\n",
    "    pivot_df = df.pivot_table(index=['product_id','variant_sku'], columns='month_name', values='net_quantity', aggfunc='sum', fill_value=0).reset_index()\n",
    "\n",
    "    # Reorganizar el DataFrame con las columnas por meses\n",
    "    ordered_columns = [\"product_id\", \"variant_sku\"] + months \n",
    "    pivot_df = pivot_df[ordered_columns]\n",
    "\n",
    "    # Organizar el DataFrame pivotado según la cantidad total de ventas por SKU\n",
    "    pivot_df['Total'] = pivot_df[months].sum(axis=1)\n",
    "    pivot_df = pivot_df.sort_values(by='Total', ascending=False)  # Ordenar de mayor a menor según la suma total\n",
    "\n",
    "    # Calcular la cantidad de meses con ventas         \n",
    "    pivot_df[\"MonthsWithSales\"] = pivot_df.apply(lambda row: sum(1 for month in months if row[month] > 0), axis=1) \n",
    "\n",
    "    df_filtered = pivot_df[~(pivot_df[months] == 0).all(axis=1)]\n",
    "\n",
    "    inventario = inventario2\n",
    "\n",
    "    # Convierte ambas columnas a tipo de dato str\n",
    "    #pivot_df['variant_sku'] = pivot_df['variant_sku'].astype(str)\n",
    "    #inventario['Variant SKU'] = inventario['Variant SKU'].astype(str)\n",
    "\n",
    "    # Convierte ambas columnas a tipo de dato str\n",
    "    pivot_df['product_id'] = pivot_df['product_id'].astype('Int64')\n",
    "    inventario['ID'] = inventario['ID'].astype('Int64')\n",
    "\n",
    "    columnas_deseadas_inventario = ['ID', 'Vendor', 'Type', 'Variant SKU', 'Created At', 'Inventory Available: Bukz Tesoro', 'Inventory Available: Bukz Mattelsa', 'Inventory Available: Bukz Las Lomas', 'Inventory Available: Cedi Lomas']\n",
    "    inventario = inventario[columnas_deseadas_inventario].copy()  # Añade .copy() aquí\n",
    "    inventario[['Inventory Available: Bukz Tesoro', 'Inventory Available: Bukz Mattelsa', 'Inventory Available: Bukz Las Lomas', 'Inventory Available: Cedi Lomas']] = inventario[['Inventory Available: Bukz Tesoro', 'Inventory Available: Bukz Mattelsa', 'Inventory Available: Bukz Las Lomas', 'Inventory Available: Cedi Lomas']].apply(lambda x: abs(x))\n",
    "\n",
    "    # Realiza el cruce con las columnas convertidas\n",
    "    df_resultado = pd.merge(pivot_df, inventario, left_on='product_id', right_on='ID', how='left')\n",
    "    df_resultado = df_resultado.dropna(subset=['Variant SKU'])\n",
    "\n",
    "    # Convierte la columna \"Created At\" al tipo de datos datetime si aún no lo está\n",
    "    df_resultado['Created At'] = pd.to_datetime(df_resultado['Created At'])\n",
    "\n",
    "    # Obtiene la fecha actual\n",
    "    fecha_actual = datetime.now()\n",
    "\n",
    "    # Calcula la diferencia en meses entre la fecha actual y la columna \"Created At\" en formato decimal\n",
    "    df_resultado['meses de creación'] = ((fecha_actual - df_resultado['Created At']).dt.total_seconds() / (30 * 24 * 60 * 60)).round(1)\n",
    "\n",
    "    # Aplicar todas las reglas en secuencia:\n",
    "    def apply_all_rules(df, months, inv_sede):\n",
    "        month_columns = [col for col in df.columns if col in months]\n",
    "        df['sugerido'] = np.nan\n",
    "        df['tipo_caso'] = \"\"\n",
    "\n",
    "        df = set_suggested_for_old_books(df)\n",
    "        df = set_suggested_for_months_with_sales(df)\n",
    "        df = set_suggested_for_recent_creation(df)\n",
    "        df = set_suggested_for_intermittent_sales(df, month_columns)\n",
    "        df = set_suggested_for_no_inventory(df, inv_sede)\n",
    "        df = set_suggested_for_recent_creation_with_low_sales(df)\n",
    "        df = set_suggested_for_average_sales(df, months)\n",
    "\n",
    "        # Handle NaNs in 'sugerido'\n",
    "        mask_sugerido_nan = df['sugerido'].isna()\n",
    "        df.loc[mask_sugerido_nan, 'sugerido'] = df[mask_sugerido_nan].apply(compute_six_month_average, axis=1).round(0)\n",
    "        df.loc[mask_sugerido_nan, 'tipo_caso'] = \"Promedio de ventas de 6 meses\"\n",
    "\n",
    "        df.loc[df['sugerido'] == 0, 'sugerido'] = 1\n",
    "        df = df.drop(\"intermittent\", axis=1)\n",
    "\n",
    "        return df\n",
    "\n",
    "    df_resultado = apply_all_rules(df_resultado, months, inv_sede)\n",
    "\n",
    "    # Crear la columna 'sugerido_2' inicialmente con NaNs\n",
    "    df_resultado['sugerido_2'] = np.nan\n",
    "    df_resultado['meses de inventario'] = \"\"\n",
    "\n",
    "    # Aplicamos la función y asignamos los resultados al DataFrame\n",
    "    df_resultado[['sugerido_2', 'meses de inventario']] = df_resultado.apply(compute_values, axis=1)\n",
    "\n",
    "    # Realizar la operación de resta\n",
    "    df_resultado['Estado_inventario'+sede] = df_resultado[inv_sede] - df_resultado['sugerido_2']\n",
    "    \n",
    "    df_resultado.to_excel(f\"resultado_{sede}.xlsx\")\n",
    "    \n",
    "    resultados[sede] = df_resultado.copy()\n",
    "    \n",
    "    print(\"Completo \" + sede)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98816634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582\n",
      "3702\n",
      "3216\n",
      "7500\n"
     ]
    }
   ],
   "source": [
    "df_Mattelsa = resultados['Bukz Mattelsa']\n",
    "df_Lomas = resultados['Bukz Las Lomas']\n",
    "df_Tesoro = resultados['Bukz Tesoro']\n",
    "\n",
    "print(len(df_Mattelsa))\n",
    "print(len(df_Lomas))\n",
    "print(len(df_Tesoro))\n",
    "print(len(df_Mattelsa)+len(df_Lomas)+len(df_Tesoro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2674b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tesoro = df_Tesoro.drop_duplicates(subset=['product_id'])\n",
    "df_Mattelsa = df_Mattelsa.drop_duplicates(subset=['product_id'])\n",
    "df_Lomas = df_Lomas.drop_duplicates(subset=['product_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9a0fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Tesoro = df_Tesoro[df_Tesoro['meses de creación'] > 1]\n",
    "df_Mattelsa = df_Mattelsa[df_Mattelsa['meses de creación'] > 1]\n",
    "df_Lomas = df_Lomas[df_Lomas['meses de creación'] > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bca4cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df_Mattelsa, df_Lomas, df_Tesoro])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7480898",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel(\"Df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2a5a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_non_nan(series):\n",
    "    return series.dropna().iloc[0] if not series.dropna().empty else np.nan\n",
    "\n",
    "# Obtener valores únicos para las columnas de interés\n",
    "unique_values = result.groupby('product_id').agg({\n",
    "    'Estado_inventarioBukz Tesoro': first_non_nan,\n",
    "    'Estado_inventarioBukz Mattelsa': first_non_nan,\n",
    "    'Estado_inventarioBukz Las Lomas': first_non_nan,\n",
    "}).reset_index()\n",
    "\n",
    "# Eliminar duplicados y combinar con los valores únicos\n",
    "result = result.drop_duplicates(subset='product_id').drop(columns=['Estado_inventarioBukz Tesoro','Estado_inventarioBukz Mattelsa', 'Estado_inventarioBukz Las Lomas'])\n",
    "result = pd.merge(result, unique_values, on='product_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['product_id'].dtypes)\n",
    "print(unique_values['product_id'].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daf6e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result.copy()\n",
    "df = df.rename(columns={'Estado_inventarioBukz Las Lomas':'Lomas', 'Estado_inventarioBukz Tesoro':'Tesoro', 'Estado_inventarioBukz Mattelsa':'Mattelsa'})\n",
    "bodegas = ['Lomas', 'Tesoro', 'Mattelsa']\n",
    "df = df.drop_duplicates()\n",
    "# Agregamos las columnas de transferencia y devolución\n",
    "for i in bodegas:\n",
    "    for j in bodegas:\n",
    "        if i != j:\n",
    "            df[f\"De {i} a {j}\"] = 0.0\n",
    "    df[f\"Devolver de {i}\"] = 0.0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    while True:\n",
    "        deficit = {bodega: row[bodega] for bodega in bodegas if row[bodega] < 0}\n",
    "        exceso = {bodega: row[bodega] for bodega in bodegas if row[bodega] > 0}\n",
    "\n",
    "        # Si no hay bodegas en déficit o en exceso, rompemos el ciclo\n",
    "        if not deficit or not exceso:\n",
    "            break\n",
    "\n",
    "        # Tomamos la bodega con mayor déficit y la de mayor exceso\n",
    "        bodega_deficit = min(deficit, key=deficit.get)\n",
    "        bodega_exceso = max(exceso, key=exceso.get)\n",
    "\n",
    "        # Calculamos cuánto mover\n",
    "        cantidad_mover = min(abs(row[bodega_deficit]), row[bodega_exceso])\n",
    "\n",
    "        # Actualizamos la columna de transferencia y los valores de las bodegas\n",
    "        df.at[index, f\"De {bodega_exceso} a {bodega_deficit}\"] += cantidad_mover\n",
    "        row[bodega_deficit] += cantidad_mover\n",
    "        row[bodega_exceso] -= cantidad_mover\n",
    "\n",
    "# Actualización de la cantidad a devolver teniendo en cuenta lo enviado\n",
    "for bodega in bodegas:\n",
    "    libros_enviados = df[[col for col in df.columns if col.startswith(f\"De {bodega}\")]].sum(axis=1)\n",
    "    df[f\"Devolver de {bodega}\"] = df[bodega] - libros_enviados\n",
    "    df[f\"Devolver de {bodega}\"] = df[f\"Devolver de {bodega}\"].apply(lambda x: x if x > 0 else 0)\n",
    "    \n",
    "# 1. Suma todas las transferencias por bodega\n",
    "transferencias_lomas = df['De Mattelsa a Lomas'] + df['De Tesoro a Lomas']\n",
    "transferencias_tesoro = df['De Mattelsa a Tesoro'] + df['De Lomas a Tesoro']\n",
    "transferencias_mattelsa = df['De Lomas a Mattelsa'] + df['De Tesoro a Mattelsa']\n",
    "\n",
    "# 2. Resta estas sumas del inventario original para obtener el inventario final\n",
    "df['Lomas final'] = df['Lomas'] + transferencias_lomas\n",
    "df['Tesoro final'] = df['Tesoro'] + transferencias_tesoro\n",
    "df['Mattelsa final'] = df['Mattelsa'] + transferencias_mattelsa\n",
    "\n",
    "# 3. Determina cuántos libros hay que pedir basándote en los negativos del inventario final\n",
    "df['Pedir Lomas'] = df['Lomas final'].apply(lambda x: abs(x) if x < 0 else 0)\n",
    "df['Pedir Tesoro'] = df['Tesoro final'].apply(lambda x: abs(x) if x < 0 else 0)\n",
    "df['Pedir Mattelsa'] = df['Mattelsa final'].apply(lambda x: abs(x) if x < 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3404d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"datos.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fae8419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de condiciones y asignaciones para cada sede\n",
    "sedes = {\n",
    "    'Mattelsa': 'De Mattelsa a CEDI',\n",
    "    'Las Lomas': 'De Lomas a CEDI',\n",
    "    'Tesoro': 'De Tesoro a CEDI'\n",
    "}\n",
    "\n",
    "for sede, new_col in sedes.items():\n",
    "    condition = result[f'Estado_inventarioBukz {sede}'] > 0\n",
    "    result[new_col] = np.where(condition, result[f'Estado_inventarioBukz {sede}'].abs(), np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88286b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['devolver_a_CEDI'] = result[['De Mattelsa a CEDI', 'De Lomas a CEDI', 'De Tesoro a CEDI']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69692c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['total_CEDI'] = result[['devolver_a_CEDI','Inventory Available: Cedi Lomas']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5665b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear columnas para rastrear los libros enviados de CEDI a cada sede\n",
    "for col in result.columns:\n",
    "    if 'Estado_inventarioBukz' in col:\n",
    "        result[f'De CEDI_a_{col.split()[-1]}'] = 0\n",
    "\n",
    "# Crear una copia del total_CEDI para trabajar sin modificar la original\n",
    "result['total_CEDI_copia'] = result['total_CEDI']\n",
    "\n",
    "for idx, row in result.iterrows():\n",
    "    # Obtener los déficits\n",
    "    deficits = {col: row[col] for col in result.columns if 'Estado_inventarioBukz' in col and row[col] < 0}\n",
    "    total_deficit = sum(abs(value) for value in deficits.values())\n",
    "\n",
    "    # Cuántos libros realmente se pueden enviar desde CEDI para este row\n",
    "    dispatchable_books = min(row['total_CEDI_copia'], total_deficit)\n",
    "    \n",
    "    # Si no hay libros para enviar, continuar con la siguiente fila\n",
    "    if dispatchable_books == 0:\n",
    "        continue\n",
    "\n",
    "    for col, deficit in deficits.items():\n",
    "        # Calcular la proporción del déficit de esta sede\n",
    "        proportion = abs(deficit) / total_deficit\n",
    "\n",
    "        # Calcular la cantidad de libros a enviar basados en la proporción\n",
    "        amount_to_send = int(dispatchable_books * proportion)\n",
    "        \n",
    "        # Actualizar las columnas relevantes\n",
    "        result.at[idx, col] += amount_to_send\n",
    "        result.at[idx, f'De CEDI_a_{col.split()[-1]}'] += amount_to_send\n",
    "        result.at[idx, 'total_CEDI_copia'] -= amount_to_send\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de5f7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, _ in result.iterrows():\n",
    "    # Identificar sedes con déficit y ordenarlas\n",
    "    deficits = {col: result.at[idx, col] for col in result.columns if 'Estado_inventarioBukz' in col and result.at[idx, col] < 0}\n",
    "    sorted_deficits = sorted(deficits, key=lambda k: deficits[k])\n",
    "    \n",
    "    # Distribuir libros desde CEDI a las sedes, de mayor a menor déficit\n",
    "    for sede in sorted_deficits:\n",
    "        if result.at[idx, 'total_CEDI_copia'] > 0:  # Si hay libros en CEDI\n",
    "            result.at[idx, sede] += 1  # Sumar 1 libro al déficit de la sede\n",
    "            result.at[idx, f'De CEDI_a_{sede.split()[-1]}'] += 1  # Registrar que se envió un libro desde CEDI a la sede\n",
    "            result.at[idx, 'total_CEDI_copia'] -= 1  # Restar 1 libro de CEDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "003d3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar las nuevas columnas\n",
    "for sede in [\"Tesoro\", \"Mattelsa\", \"Las Lomas\"]:\n",
    "    result[f\"pedir_{sede}\"] = 0\n",
    "\n",
    "# Actualizar las nuevas columnas según las condiciones\n",
    "for idx, _ in result.iterrows():\n",
    "    for sede in [\"Tesoro\", \"Mattelsa\", \"Las Lomas\"]:\n",
    "        original_column = f\"Estado_inventarioBukz {sede}\"\n",
    "        if result.at[idx, original_column] < 0:\n",
    "            result.at[idx, f\"pedir_{sede}\"] = abs(result.at[idx, original_column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f23f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns_mattelsa = ['product_id', 'variant_sku', 'Vendor','Inventory Available: Bukz Mattelsa','sugerido', 'meses de inventario', \n",
    "       'sugerido_2','Estado_inventarioBukz Mattelsa', 'meses de creación']\n",
    "df_Mattelsa_new = df_Mattelsa[selected_columns_mattelsa].copy()\n",
    "\n",
    "selected_columns_Tesoro = ['product_id', 'variant_sku', 'Vendor','Inventory Available: Bukz Tesoro','sugerido', 'meses de inventario', \n",
    "       'sugerido_2','Estado_inventarioBukz Tesoro', 'meses de creación']\n",
    "df_Tesoro_new = df_Tesoro[selected_columns_Tesoro].copy()\n",
    "\n",
    "selected_columns_lomas = ['product_id', 'variant_sku', 'Vendor','Inventory Available: Bukz Las Lomas','sugerido', 'meses de inventario', \n",
    "       'sugerido_2','Estado_inventarioBukz Las Lomas', 'meses de creación']\n",
    "df_Lomas_new = df_Lomas[selected_columns_lomas].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ea44f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona solo las columnas deseadas de df2\n",
    "selected_columns = ['product_id', 'De Lomas a CEDI', 'De CEDI_a_Lomas', 'pedir_Las Lomas', 'total_CEDI_copia']\n",
    "cruzar_lomas = result[selected_columns].copy()\n",
    "\n",
    "# Realiza el merge\n",
    "Lomas_final = pd.merge(df_Lomas_new, cruzar_lomas, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bfcaf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona solo las columnas deseadas de df2\n",
    "selected_columns_tesoro = ['product_id', 'De Tesoro a CEDI', 'De CEDI_a_Tesoro', 'pedir_Tesoro', 'total_CEDI_copia']\n",
    "cruzar_tesoro = result[selected_columns_tesoro].copy()\n",
    "\n",
    "# Realiza el merge\n",
    "Tesoro_final = pd.merge(df_Tesoro_new, cruzar_tesoro, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "122d5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona solo las columnas deseadas de df2\n",
    "selected_columns_mattelsa = ['product_id', 'De Mattelsa a CEDI', 'De CEDI_a_Mattelsa', 'pedir_Mattelsa', 'total_CEDI_copia']\n",
    "cruzar_Mattelsa = result[selected_columns_mattelsa].copy()\n",
    "\n",
    "# Realiza el merge\n",
    "Mattelsa_final = pd.merge(df_Mattelsa_new, cruzar_Mattelsa, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "721fee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_inventario(df_original, columna_inventario, df_final):\n",
    "    vendors_excluidos = ['Bukz USA', 'Bukz España']\n",
    "    \n",
    "    # Filtrar el DataFrame por los criterios deseados\n",
    "    filtered_df = df_original[df_original[columna_inventario].notna() & \n",
    "                              (df_original[columna_inventario] > 0) & \n",
    "                              (~df_original['Vendor'].isin(vendors_excluidos))]  # Esta línea excluye las filas con los Vendors especificados\n",
    "    \n",
    "    filtered_df = filtered_df[filtered_df['Type'].isin(['Libro', 'Libros', 'Libros impresos'])].copy()\n",
    "    filtered_df[columna_inventario] = filtered_df[columna_inventario].apply(lambda x: 0 if x < 0 else x)\n",
    "    filtered_df.rename(columns={'ID': 'product_id'}, inplace=True)\n",
    "    \n",
    "    no_ventas = filtered_df.merge(df_final, on='product_id', how='left', indicator=True)\n",
    "    no_ventas = no_ventas[no_ventas['_merge'] == 'left_only']\n",
    "    no_ventas = no_ventas.drop(columns=['_merge'])\n",
    "    \n",
    "    no_ventas['Created At'] = pd.to_datetime(no_ventas['Created At'])\n",
    "    fecha_actual = datetime.now()\n",
    "    no_ventas['meses de creación'] = ((fecha_actual - no_ventas['Created At']).dt.total_seconds() / (30 * 24 * 60 * 60)).round(1)\n",
    "    \n",
    "    return no_ventas\n",
    "\n",
    "# Aplicar la función para cada sede\n",
    "no_ventas_lomas = procesar_inventario(inventario_original, 'Inventory Available: Bukz Las Lomas', Lomas_final)\n",
    "no_ventas_Tesoro = procesar_inventario(inventario_original, 'Inventory Available: Bukz Tesoro', Tesoro_final)\n",
    "no_ventas_Mattelsa = procesar_inventario(inventario_original, 'Inventory Available: Bukz Mattelsa', Mattelsa_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99c0e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_envio(row, col_inventario):\n",
    "    meses = row[\"meses de creación\"]\n",
    "    inventario = row[col_inventario]\n",
    "    \n",
    "    if meses <= 1:\n",
    "        return 0\n",
    "    elif 1 < meses <= 3:\n",
    "        if inventario > 3:\n",
    "            return inventario - 3\n",
    "        else:\n",
    "            return 0\n",
    "    elif 3 < meses <= 6:\n",
    "        if inventario > 2:\n",
    "            return inventario - 2\n",
    "        else:\n",
    "            return 0\n",
    "    else: # si meses > 6\n",
    "        if inventario > 1:\n",
    "            return inventario - 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# Para Lomas\n",
    "no_ventas_lomas[\"enviar_CEDI_no_ventas_Lomas\"] = no_ventas_lomas.apply(calcular_envio, args=(\"Inventory Available: Bukz Las Lomas_x\",), axis=1)\n",
    "\n",
    "# Para Tesoro\n",
    "no_ventas_Tesoro[\"enviar_CEDI_no_ventas_Tesoro\"] = no_ventas_Tesoro.apply(calcular_envio, args=(\"Inventory Available: Bukz Tesoro_x\",), axis=1)  # Asumiendo que esta es la columna correcta\n",
    "\n",
    "# Para Mattelsa\n",
    "no_ventas_Mattelsa[\"enviar_CEDI_no_ventas_Mattelsa\"] = no_ventas_Mattelsa.apply(calcular_envio, args=(\"Inventory Available: Bukz Mattelsa_x\",), axis=1)  # Asumiendo que esta es la columna correcta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e71bd82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando los DataFrames\n",
    "df_concatenado_Lomas = pd.concat([Lomas_final, no_ventas_lomas], ignore_index=True)\n",
    "df_concatenado_Mattelsa = pd.concat([Mattelsa_final, no_ventas_Mattelsa], ignore_index=True)\n",
    "df_concatenado_Tesoro = pd.concat([Tesoro_final, no_ventas_Tesoro], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1d9b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer los 'variant_id' de cada DataFrame y convertirlos en conjuntos\n",
    "ids_lomas = set(no_ventas_lomas['product_id'])\n",
    "ids_Tesoro = set(no_ventas_Tesoro['product_id'])\n",
    "ids_Mattelsa = set(no_ventas_Mattelsa['product_id'])\n",
    "\n",
    "# Identificar los ids que están en al menos dos de los conjuntos\n",
    "ids_repetidos = (ids_lomas & ids_Tesoro) | (ids_lomas & ids_Mattelsa) | (ids_Tesoro & ids_Mattelsa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0a59837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_total(df_resultado, df_no_ventas, columna_enviar):\n",
    "    \"\"\"\n",
    "    Esta función toma el DataFrame resultado y actualiza la columna 'total_CEDI_copia'\n",
    "    sumando los valores de la columna enviar de df_no_ventas.\n",
    "    \"\"\"\n",
    "    # Realizamos un merge en base a 'variant_id'\n",
    "    merged_df = df_resultado.merge(df_no_ventas[['product_id', columna_enviar]], on='product_id', how='left')\n",
    "    \n",
    "    # Rellenamos los NaN con 0 (esto es para aquellos variant_id que no existen en df_no_ventas)\n",
    "    merged_df[columna_enviar].fillna(0, inplace=True)\n",
    "    \n",
    "    # Sumamos los valores al total\n",
    "    merged_df['total_CEDI_copia'] += merged_df[columna_enviar]\n",
    "    \n",
    "    # Eliminamos la columna temporal\n",
    "    merged_df.drop(columns=columna_enviar, inplace=True)\n",
    "    \n",
    "    # Extraemos los registros que no cruzaron con df_principal_copia\n",
    "    nuevos_registros = df_no_ventas[~df_no_ventas['product_id'].isin(merged_df['product_id'])].copy()\n",
    "    nuevos_registros['total_CEDI_copia'] = nuevos_registros[columna_enviar]\n",
    "    nuevos_registros = nuevos_registros[['product_id', 'total_CEDI_copia']]\n",
    "    \n",
    "    # Concatenamos al final de merged_df\n",
    "    merged_df = pd.concat([merged_df, nuevos_registros], ignore_index=True)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Creando una copia de df_principal y seleccionando las columnas deseadas\n",
    "columnas_deseadas = ['total_CEDI_copia', 'product_id']  # Agrega las columnas que desees conservar\n",
    "df_principal_copia = result[columnas_deseadas].copy()\n",
    "\n",
    "# Aplicamos la función para cada DataFrame\n",
    "df_resultado = actualizar_total(df_principal_copia, no_ventas_lomas, 'enviar_CEDI_no_ventas_Lomas')\n",
    "df_resultado = actualizar_total(df_resultado, no_ventas_Tesoro, 'enviar_CEDI_no_ventas_Tesoro')\n",
    "df_resultado = actualizar_total(df_resultado, no_ventas_Mattelsa, 'enviar_CEDI_no_ventas_Mattelsa')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f4f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sugerencia_entre_sedes(df_origen, df_destino, inventario_df, columna_inventario, nombre_sede):\n",
    "    # Cruce de registros de df_origen que no están en df_destino\n",
    "    no_en_destino = df_origen[~df_origen['product_id'].isin(df_destino['product_id'])].copy()\n",
    "\n",
    "    # Consultar inventario para esos registros\n",
    "    no_en_destino = no_en_destino.merge(inventario_df[['ID', columna_inventario]], left_on='product_id', right_on='ID', how='left')\n",
    "    no_en_destino['sugerido entre sedes'] = no_en_destino.apply(lambda row: 'enviar' if pd.isna(row[columna_inventario]) or row[columna_inventario] <= 0 else '', axis=1)\n",
    "    no_en_destino = no_en_destino[no_en_destino['sugerido entre sedes'] == 'enviar']\n",
    "    no_en_destino.drop(columns=['ID', columna_inventario], inplace=True)  # Eliminamos 'ID' y la columna de inventario\n",
    "    no_en_destino['sede'] = nombre_sede\n",
    "    \n",
    "    return no_en_destino[['product_id', 'variant_sku', 'sugerido entre sedes', 'sede', 'sugerido']]\n",
    "\n",
    "\n",
    "\n",
    "# Procesar cada combinación de DataFrames\n",
    "sugerencia_Mattelsa_Tesoro = sugerencia_entre_sedes(Mattelsa_final, Tesoro_final, inventario_original, 'Inventory Available: Bukz Tesoro', 'Tesoro')\n",
    "sugerencia_Mattelsa_Lomas = sugerencia_entre_sedes(Mattelsa_final, Lomas_final, inventario_original, 'Inventory Available: Bukz Las Lomas', 'Lomas')\n",
    "\n",
    "sugerencia_Tesoro_Mattelsa = sugerencia_entre_sedes(Tesoro_final, Mattelsa_final, inventario_original, 'Inventory Available: Bukz Mattelsa', 'Mattelsa')\n",
    "sugerencia_Tesoro_Lomas = sugerencia_entre_sedes(Tesoro_final, Lomas_final, inventario_original, 'Inventory Available: Bukz Las Lomas', 'Lomas')\n",
    "\n",
    "sugerencia_Lomas_Tesoro = sugerencia_entre_sedes(Lomas_final, Tesoro_final, inventario_original, 'Inventory Available: Bukz Tesoro', 'Tesoro')\n",
    "sugerencia_Lomas_Mattelsa = sugerencia_entre_sedes(Lomas_final, Mattelsa_final, inventario_original, 'Inventory Available: Bukz Mattelsa', 'Mattelsa')\n",
    "\n",
    "# Consolidar los DataFrames para cada sede\n",
    "\n",
    "df_Tesoro_2 = pd.concat([sugerencia_Mattelsa_Tesoro, sugerencia_Lomas_Tesoro], ignore_index=True)\n",
    "df_Lomas_2 = pd.concat([sugerencia_Tesoro_Lomas, sugerencia_Mattelsa_Lomas], ignore_index=True)\n",
    "df_Mattelsa_2 = pd.concat([sugerencia_Tesoro_Mattelsa, sugerencia_Lomas_Mattelsa], ignore_index=True)\n",
    "\n",
    "# Para df_Tesoro_2\n",
    "idx = df_Tesoro_2.groupby(['product_id'])['sugerido'].idxmin()\n",
    "df_Tesoro_2 = df_Tesoro_2.loc[idx]\n",
    "\n",
    "# para df_Lomas_2\n",
    "idx_lomas = df_Lomas_2.groupby(['product_id'])['sugerido'].idxmin()\n",
    "df_Lomas_2 = df_Lomas_2.loc[idx_lomas]\n",
    "\n",
    "# para df_Mattelsa_2\n",
    "idx_mattelsa = df_Mattelsa_2.groupby(['product_id'])['sugerido'].idxmin()\n",
    "df_Mattelsa_2 = df_Mattelsa_2.loc[idx_mattelsa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07946a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenado = pd.concat([df_Tesoro_2, df_Mattelsa_2, df_Lomas_2], ignore_index=True)\n",
    "df_concatenado = df_concatenado.drop_duplicates(subset=['product_id', 'sede'])\n",
    "\n",
    "df_concatenado = df_concatenado.pivot(index='product_id', columns='sede', values='sugerido').reset_index()\n",
    "\n",
    "# Rellenar valores NaN con 0\n",
    "df_concatenado = df_concatenado.fillna(0).astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebfcb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las columnas 'product_id' a Int64\n",
    "df_concatenado['product_id'] = df_concatenado['product_id'].astype('Int64')\n",
    "df_resultado['product_id'] = df_resultado['product_id'].astype('Int64')\n",
    "\n",
    "# Hacer el merge\n",
    "merged_df_sedes = pd.merge(df_concatenado, df_resultado, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sedes = merged_df_sedes.copy()\n",
    "\n",
    "df_sedes = merged_df_sedes.copy()\n",
    "\n",
    "# Crear columnas para almacenar la cantidad de items enviados desde el CEDI a cada tienda\n",
    "for tienda in ['Lomas', 'Mattelsa', 'Tesoro']:\n",
    "    df_sedes[f'De_CEDI_a_{tienda}'] = 0\n",
    "    df_sedes[f'Pedir_{tienda}'] = 0  # Columnas para almacenar cuánto más hay que pedir por sede\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame\n",
    "for idx, row in df_sedes.iterrows():\n",
    "    cedi_disponible = row['total_CEDI_copia']\n",
    "\n",
    "    while cedi_disponible > 0 and any(row[['Lomas', 'Mattelsa', 'Tesoro']] > 0):\n",
    "        for tienda in ['Lomas', 'Mattelsa', 'Tesoro']:\n",
    "            if row[tienda] > 0 and cedi_disponible > 0:\n",
    "                df_sedes.at[idx, tienda] -= 1\n",
    "                cedi_disponible -= 1\n",
    "                \n",
    "                df_sedes.at[idx, f'De_CEDI_a_{tienda}'] += 1\n",
    "                \n",
    "                df_sedes.at[idx, 'total_CEDI_copia'] = cedi_disponible\n",
    "                row = df_sedes.loc[idx]\n",
    "\n",
    "    # Llenar las columnas de 'pedir' después de distribuir lo que se pudo desde el CEDI\n",
    "    for tienda in ['Lomas', 'Mattelsa', 'Tesoro']:\n",
    "        # Se calcula cuánto más hay que pedir por sede, teniendo en cuenta los ya enviados desde el CEDI\n",
    "        df_sedes.at[idx, f'Pedir_{tienda}'] = df_sedes.at[idx, tienda] - df_sedes.at[idx, f'De_CEDI_a_{tienda}']\n",
    "\n",
    "\n",
    "        \n",
    "df_sedes = df_sedes[[\"product_id\", \"Lomas\", \"Mattelsa\", \"Tesoro\", \"total_CEDI_copia\", \"De_CEDI_a_Lomas\", \"De_CEDI_a_Mattelsa\",  \n",
    "                     \"De_CEDI_a_Tesoro\", \"Pedir_Lomas\", \"Pedir_Mattelsa\", \"Pedir_Tesoro\"]]\n",
    "\n",
    "df_sedes = df_sedes[[\"product_id\", \"Lomas\", \"Mattelsa\", \"Tesoro\", \"total_CEDI_copia\", \"De_CEDI_a_Lomas\", \"De_CEDI_a_Mattelsa\",  \n",
    "                     \"De_CEDI_a_Tesoro\", \"Pedir_Lomas\", \"Pedir_Mattelsa\", \"Pedir_Tesoro\"]]\n",
    "\n",
    "\n",
    "df1_unique = df1.drop_duplicates(subset=['product_id'])\n",
    "merged_sedes = pd.merge(df_sedes, df1_unique[['product_id', 'product_title', 'variant_sku', 'product_vendor']], on='product_id', how='left')\n",
    "merged_sedes = merged_sedes.rename(columns={'product_id': 'ID', 'product_title':'Titulo','variant_sku':'SKU', 'product_vendor':'Vendor'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce730aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distribucion_Lomas = merged_sedes[['ID','Titulo', 'SKU', 'Vendor', 'Lomas', 'De_CEDI_a_Lomas', 'Pedir_Lomas']].copy()\n",
    "df_distribucion_Lomas = df_distribucion_Lomas[df_distribucion_Lomas['Lomas'] != 0].reset_index(drop=True)\n",
    "df_distribucion_Lomas = df_distribucion_Lomas.rename(columns={'Lomas': 'Sugerido'})\n",
    "df_distribucion_Lomas = df_distribucion_Lomas.sort_values(by='Sugerido', ascending=False)\n",
    "\n",
    "\n",
    "df_distribucion_Mattelsa = merged_sedes[['ID','Titulo', 'SKU', 'Vendor', 'Mattelsa', 'De_CEDI_a_Mattelsa', 'Pedir_Mattelsa']].copy()\n",
    "df_distribucion_Mattelsa = df_distribucion_Mattelsa[df_distribucion_Mattelsa['Mattelsa'] != 0].reset_index(drop=True)\n",
    "df_distribucion_Mattelsa = df_distribucion_Mattelsa.rename(columns={'Mattelsa': 'Sugerido'})\n",
    "df_distribucion_Mattelsa = df_distribucion_Mattelsa.sort_values(by='Sugerido', ascending=False)\n",
    "\n",
    "\n",
    "df_distribucion_Tesoro = merged_sedes[['ID','Titulo', 'SKU', 'Vendor', 'Tesoro', 'De_CEDI_a_Tesoro', 'Pedir_Tesoro']].copy()\n",
    "df_distribucion_Tesoro = df_distribucion_Tesoro[df_distribucion_Tesoro['Tesoro'] != 0].reset_index(drop=True)\n",
    "df_distribucion_Tesoro = df_distribucion_Tesoro.rename(columns={'Tesoro': 'Sugerido'})\n",
    "df_distribucion_Tesoro = df_distribucion_Tesoro.sort_values(by='Sugerido', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201009a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df, column_mapping):\n",
    "    df.rename(columns=column_mapping, inplace=True)\n",
    "    \n",
    "def drop_columns(df, columns_to_drop):\n",
    "    columns_to_drop_actual = [col for col in columns_to_drop if col in df.columns]\n",
    "    return df.drop(columns_to_drop_actual, axis=1)\n",
    "\n",
    "# Mapeo para Lomas_final\n",
    "lomas_mapping = {'product_id': 'ID','variant_sku': 'SKU', 'Inventory Available: Bukz Las Lomas': 'Inventario_Actual','sugerido': 'Sugerido_Mensual',\n",
    "    'meses de inventario': 'Meses_de_Inventario','sugerido_2': 'Sugerido_Final','Estado_inventarioBukz Las Lomas': 'Estado_Inventario','De Lomas a CEDI': 'De_Lomas_a_CEDI',\n",
    "    'De CEDI_a_Lomas': 'De CEDI_a_Lomas','pedir_Las Lomas': 'Pedir_Lomas'}\n",
    "\n",
    "# Mapeo para Tesoro_final\n",
    "tesoro_mapping = {'product_id': 'ID','variant_sku': 'SKU','Inventory Available: Bukz Tesoro': 'Inventario_Actual','sugerido': 'Sugerido_Mensual',\n",
    "    'meses de inventario': 'Meses_de_Inventario','sugerido_2': 'Sugerido_Final','Estado_inventarioBukz Tesoro': 'Estado_Inventario','De Tesoro a CEDI': 'De_Tesoro_a_CEDI',\n",
    "    'De CEDI_a_Tesoro': 'De CEDI_a_Tesoro','pedir_Tesoro': 'Pedir_Tesoro'}\n",
    "\n",
    "# Mapeo para Mattelsa_final\n",
    "mattelsa_mapping = {'product_id': 'ID', 'variant_sku': 'SKU', 'Inventory Available: Bukz Mattelsa': 'Inventario_Actual', 'sugerido': 'Sugerido_Mensual',\n",
    "    'meses de inventario': 'Meses_de_Inventario','sugerido_2': 'Sugerido_Final','Estado_inventarioBukz Mattelsa': 'Estado_Inventario','De Mattelsa a CEDI': 'De_Mattelsa_a_CEDI',\n",
    "    'De CEDI_a_Mattelsa': 'De CEDI_a_Mattelsa','pedir_Mattelsa': 'Pedir_Mattelsa'}\n",
    "\n",
    "# Renombrar columnas usando la función y mapeos\n",
    "rename_columns(Lomas_final, lomas_mapping)\n",
    "rename_columns(Tesoro_final, tesoro_mapping)\n",
    "rename_columns(Mattelsa_final, mattelsa_mapping)\n",
    "\n",
    "# Definir las columnas a eliminar\n",
    "columns_to_drop = ['meses de creación', 'total_CEDI_copia']\n",
    "\n",
    "# Aplicar la función\n",
    "Lomas_final = drop_columns(Lomas_final, columns_to_drop)\n",
    "Tesoro_final = drop_columns(Tesoro_final, columns_to_drop)\n",
    "Mattelsa_final = drop_columns(Mattelsa_final, columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64380c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df, column_mapping):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.rename(columns=column_mapping, inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "df_no_ventas_Lomas = no_ventas_lomas[['product_id', 'Variant SKU','Inventory Available: Bukz Las Lomas_x','Created At', \n",
    "                                      'enviar_CEDI_no_ventas_Lomas']]\n",
    "lomas_mapping2 = {'product_id':'ID', 'Variant SKU': 'SKU', 'Inventory Available: Bukz Las Lomas_x': 'Inventario_Actual',\n",
    "                 'Created At':'Fecha_Creación', 'enviar_CEDI_no_ventas_Lomas':'De_Lomas_a_CEDI'}\n",
    "df_no_ventas_Lomas = rename_columns(df_no_ventas_Lomas, lomas_mapping2)\n",
    "df_no_ventas_Lomas['Fecha_Creación'] = pd.to_datetime(df_no_ventas_Lomas['Fecha_Creación']).dt.date\n",
    "\n",
    "\n",
    "\n",
    "df_no_ventas_Tesoro = no_ventas_Tesoro[['product_id', 'Variant SKU','Inventory Available: Bukz Tesoro_x','Created At', \n",
    "                                      'enviar_CEDI_no_ventas_Tesoro']]\n",
    "tesoro_mapping2 = {'product_id':'ID', 'Variant SKU': 'SKU', 'Inventory Available: Bukz Tesoro_x': 'Inventario_Actual',\n",
    "                 'Created At':'Fecha_Creación', 'enviar_CEDI_no_ventas_Tesoro':'De_Tesoro_a_CEDI'}\n",
    "df_no_ventas_Tesoro = rename_columns(df_no_ventas_Tesoro, tesoro_mapping2)\n",
    "df_no_ventas_Tesoro['Fecha_Creación'] = pd.to_datetime(df_no_ventas_Tesoro['Fecha_Creación']).dt.date\n",
    "\n",
    "\n",
    "df_no_ventas_Mattelsa = no_ventas_Mattelsa[['product_id', 'Variant SKU','Inventory Available: Bukz Mattelsa_x','Created At', \n",
    "                                      'enviar_CEDI_no_ventas_Mattelsa']]\n",
    "mattelsa_mapping2 = {'product_id':'ID', 'Variant SKU': 'SKU', 'Inventory Available: Bukz Mattelsa_x': 'Inventario_Actual',\n",
    "                 'Created At':'Fecha_Creación', 'enviar_CEDI_no_ventas_Mattelsa':'De_Mattelsa_a_CEDI'}\n",
    "df_no_ventas_Mattelsa = rename_columns(df_no_ventas_Mattelsa, mattelsa_mapping2)\n",
    "df_no_ventas_Mattelsa['Fecha_Creación'] = pd.to_datetime(df_no_ventas_Mattelsa['Fecha_Creación']).dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3383dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sede_copy = df_sedes.copy()\n",
    "\n",
    "df_sede_copy['total_enviado'] = df_sede_copy['De_CEDI_a_Lomas'] + df_sede_copy['De_CEDI_a_Mattelsa'] + df_sede_copy['De_CEDI_a_Tesoro']\n",
    "\n",
    "df_sede_copy = df_sede_copy[['product_id', 'total_enviado']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef190cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sede_copy['product_id'] = df_sede_copy['product_id'].astype('Int64')\n",
    "df_resultado['product_id'] = df_resultado['product_id'].astype('Int64')\n",
    "\n",
    "merged_df_sedes_inv = pd.merge(df_resultado, df_sede_copy, on='product_id', how='left')\n",
    "\n",
    "merged_df_sedes_inv['total_CEDI_copia_updated'] = merged_df_sedes_inv.apply(\n",
    "    lambda row: row['total_CEDI_copia'] if pd.isna(row['total_enviado']) else row['total_CEDI_copia'] - row['total_enviado'],\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff0ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_cedi = merged_df_sedes_inv[['product_id','total_CEDI_copia_updated']].copy()\n",
    "inv_cedi['product_id'] = inv_cedi['product_id'].astype('Int64')\n",
    "\n",
    "mask_type = inventario_original['Type'] == 'Libro'\n",
    "mask_vendor = ~inventario_original['Vendor'].isin(['Bukz USA', 'Bukz España'])\n",
    "inv_cei_tem = inventario_original[mask_type & mask_vendor][['ID', 'Inventory Available: Cedi Lomas']].copy()\n",
    "inv_cei_tem['ID'] = inv_cei_tem['ID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_cei_tem_filtered = inv_cei_tem[inv_cei_tem['Inventory Available: Cedi Lomas'] > 0]\n",
    "\n",
    "inv_cedi_general = pd.merge(inv_cedi, inv_cei_tem_filtered, left_on='product_id', right_on='ID', how='outer')\n",
    "\n",
    "inv_cedi_general['ID'].fillna(inv_cedi_general['product_id'], inplace=True)\n",
    "inv_cedi_general['total_CEDI_copia_updated'].fillna(inv_cedi_general['Inventory Available: Cedi Lomas'], inplace=True)\n",
    "\n",
    "inv_cedi_general.drop(columns=['product_id','Inventory Available: Cedi Lomas'], inplace=True)\n",
    "inv_cedi_general = inv_cedi_general[inv_cedi_general['total_CEDI_copia_updated'] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606cf574",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_ventas_Lomas['ID'] = df_no_ventas_Lomas['ID'].astype('Int64')\n",
    "Lomas_final['ID'] = Lomas_final['ID'].astype('Int64')\n",
    "df_distribucion_Lomas['ID'] = df_distribucion_Lomas['ID'].astype('Int64')\n",
    "df_comcat_lomas = pd.concat([df_no_ventas_Lomas[['ID']], Lomas_final[['ID']], df_distribucion_Lomas[['ID']]], ignore_index=True).drop_duplicates()\n",
    "\n",
    "\n",
    "df_no_ventas_Tesoro['ID'] = df_no_ventas_Tesoro['ID'].astype('Int64')\n",
    "Tesoro_final['ID'] = Tesoro_final['ID'].astype('Int64')\n",
    "df_distribucion_Tesoro['ID'] = df_distribucion_Tesoro['ID'].astype('Int64')\n",
    "df_comcat_tesoro = pd.concat([df_no_ventas_Tesoro[['ID']], Tesoro_final[['ID']], df_distribucion_Tesoro[['ID']]], ignore_index=True).drop_duplicates()\n",
    "\n",
    "\n",
    "df_no_ventas_Mattelsa['ID'] = df_no_ventas_Mattelsa['ID'].astype('Int64')\n",
    "Mattelsa_final['ID'] = Mattelsa_final['ID'].astype('Int64')\n",
    "df_distribucion_Mattelsa['ID'] = df_distribucion_Mattelsa['ID'].astype('Int64')\n",
    "df_comcat_matt = pd.concat([df_no_ventas_Mattelsa[['ID']], Mattelsa_final[['ID']], df_distribucion_Mattelsa[['ID']]], ignore_index=True).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d6525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_matt_no_match = pd.merge(inv_cedi_general, df_comcat_matt,  on='ID', how='left',  indicator=True)\n",
    "df_concat_matt_no_match = df_concat_matt_no_match[df_concat_matt_no_match['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "df_concat_matt_no_match[\"sede\"] = \"Mattelsa\"\n",
    "\n",
    "df_concat_tesoro_no_match = pd.merge(inv_cedi_general, df_comcat_tesoro,  on='ID', how='left',  indicator=True)\n",
    "df_concat_tesoro_no_match = df_concat_tesoro_no_match[df_concat_tesoro_no_match['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "df_concat_tesoro_no_match[\"sede\"] = \"Tesoro\"\n",
    "\n",
    "df_concat_lomas_no_match = pd.merge(inv_cedi_general, df_comcat_lomas,  on='ID', how='left',  indicator=True)\n",
    "df_concat_lomas_no_match = df_concat_lomas_no_match[df_concat_lomas_no_match['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "df_concat_lomas_no_match[\"sede\"] = \"Lomas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b0bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_concat_lomas_no_match, df_concat_tesoro_no_match, df_concat_matt_no_match]\n",
    "df_concatenado_frames = pd.concat(frames, ignore_index=True)\n",
    "df_concatenado_frames = df_concatenado_frames.drop_duplicates(subset=['ID', 'sede'])\n",
    "df_concatenado_frames['presencia'] = 1\n",
    "df_pivot_presencia = df_concatenado_frames.pivot_table(index='ID', columns='sede', values='presencia', fill_value=0).reset_index()\n",
    "df_pivot_presencia_cedi = df_concatenado_frames.groupby('ID')['total_CEDI_copia_updated'].first().reset_index()\n",
    "df_pivot_presencia_cedi = pd.merge(df_pivot_presencia_cedi, df_pivot_presencia, on='ID', how='outer')\n",
    "\n",
    "mask = ~((df_pivot_presencia_cedi[['Lomas', 'Mattelsa', 'Tesoro']].sum(axis=1) == 3) & \n",
    "         (df_pivot_presencia_cedi['total_CEDI_copia_updated'].isin([1, 2]))) | (\n",
    "        (df_pivot_presencia_cedi[['Lomas', 'Mattelsa', 'Tesoro']].sum(axis=1) == 2) &\n",
    "        (df_pivot_presencia_cedi['total_CEDI_copia_updated'] == 1)\n",
    "    )\n",
    "df_pivot_presencia_cedi_2 = df_pivot_presencia_cedi[mask].copy()\n",
    "# Función para determinar la cantidad de libros a enviar\n",
    "def libros_a_enviar(row, col_name):\n",
    "    if row['total_CEDI_copia_updated'] >= 6 and row[col_name] == 1:\n",
    "        return 2\n",
    "    elif row['total_CEDI_copia_updated'] < 6 and row[col_name] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Crear nuevas columnas para cada sede, indicando cuántos libros enviar\n",
    "sedes = ['Lomas', 'Mattelsa', 'Tesoro']\n",
    "for sede in sedes:\n",
    "    df_pivot_presencia_cedi_2[f'De_CEDI_a_{sede}'] = df_pivot_presencia_cedi_2.apply(lambda row: libros_a_enviar(row, sede), axis=1)\n",
    "\n",
    "# Actualizando total_CEDI_copia_updated después de distribuir los libros\n",
    "df_pivot_presencia_cedi_2['total_CEDI_copia_updated'] = df_pivot_presencia_cedi_2['total_CEDI_copia_updated'] - df_pivot_presencia_cedi_2[[f'De_CEDI_a_{sede}' for sede in sedes]].sum(axis=1)\n",
    "\n",
    "# Asegurar que no hay valores negativos en 'total_CEDI_copia_updated'\n",
    "df_pivot_presencia_cedi_2['total_CEDI_copia_updated'] = df_pivot_presencia_cedi_2['total_CEDI_copia_updated'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f5e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_sort(df, sede_name, de_cedi_column):\n",
    "    mask = df[sede_name] != 0\n",
    "    filtered_df = df[mask].copy()\n",
    "    filtered_df = filtered_df[['ID', de_cedi_column]]\n",
    "    sorted_df = filtered_df.sort_values(by=de_cedi_column, ascending=False)\n",
    "    return sorted_df\n",
    "\n",
    "presencia_cedi_Tesoro = filter_and_sort(df_pivot_presencia_cedi_2, 'Tesoro', 'De_CEDI_a_Tesoro')\n",
    "presencia_cedi_Lomas = filter_and_sort(df_pivot_presencia_cedi_2, 'Lomas', 'De_CEDI_a_Lomas')\n",
    "presencia_cedi_Matelsa = filter_and_sort(df_pivot_presencia_cedi_2, 'Mattelsa', 'De_CEDI_a_Mattelsa')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e3a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [Lomas_final, Tesoro_final, Mattelsa_final]\n",
    "\n",
    "# Nombres originales de los DataFrames\n",
    "df_names = ['Lomas_final', 'Tesoro_final', 'Mattelsa_final']\n",
    "\n",
    "# Diccionario para almacenar los nuevos DataFrames\n",
    "new_dfs = {}\n",
    "\n",
    "# Crear y guardar un DataFrame \"merged\" para cada uno\n",
    "for i, df in enumerate(dfs):\n",
    "    merged_df = pd.merge(df, inventario_original[['ID', 'Title']], on='ID', how='left')\n",
    "    merged_df.rename(columns={'Title': 'Titulo'}, inplace=True)\n",
    "    \n",
    "    # Creando el nuevo nombre y asignándolo al diccionario\n",
    "    new_name = df_names[i] +'2'\n",
    "    new_dfs[new_name] = merged_df\n",
    "\n",
    "lomas_final_2 = new_dfs['Lomas_final2']\n",
    "lomas_final_2 = lomas_final_2[[\"ID\", \"Titulo\", \"SKU\", \"Vendor\", \"Inventario_Actual\", \"Sugerido_Mensual\", \"Meses_de_Inventario\", \"Sugerido_Final\", \"Estado_Inventario\", \"De_Lomas_a_CEDI\", \"De CEDI_a_Lomas\", \"Pedir_Lomas\"]]\n",
    "\n",
    "tesoro_final_2 = new_dfs['Tesoro_final2']\n",
    "tesoro_final_2 = tesoro_final_2[[\"ID\", \"Titulo\", \"SKU\", \"Vendor\", \"Inventario_Actual\", \"Sugerido_Mensual\", \"Meses_de_Inventario\", \"Sugerido_Final\", \"Estado_Inventario\", \"De_Tesoro_a_CEDI\", \"De CEDI_a_Tesoro\", \"Pedir_Tesoro\"]]\n",
    "\n",
    "mattelsa_final_2 = new_dfs['Mattelsa_final2']\n",
    "mattelsa_final_2 = mattelsa_final_2[[\"ID\", \"Titulo\", \"SKU\", \"Vendor\", \"Inventario_Actual\", \"Sugerido_Mensual\", \"Meses_de_Inventario\", \"Sugerido_Final\", \"Estado_Inventario\", \"De_Mattelsa_a_CEDI\", \"De CEDI_a_Mattelsa\", \"Pedir_Mattelsa\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc978431",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_no_ventas_Mattelsa, df_no_ventas_Tesoro, df_no_ventas_Lomas]\n",
    "\n",
    "# Nombres originales de los DataFrames\n",
    "df_names = ['df_no_ventas_Mattelsa', 'df_no_ventas_Tesoro', 'df_no_ventas_Lomas']\n",
    "\n",
    "# Diccionario para almacenar los nuevos DataFrames\n",
    "new_dfs = {}\n",
    "\n",
    "# Crear y guardar un DataFrame \"merged\" para cada uno\n",
    "for i, df in enumerate(dfs):\n",
    "    merged_df = pd.merge(df, inventario_original[['ID', 'Title', 'Vendor']], on='ID', how='left')\n",
    "    merged_df.rename(columns={'Title': 'Titulo'}, inplace=True)\n",
    "    \n",
    "    # Creando el nuevo nombre y asignándolo al diccionario\n",
    "    new_name = df_names[i] +'2'\n",
    "    new_dfs[new_name] = merged_df\n",
    "\n",
    "df_no_ventas_Mattelsa_2 = new_dfs['df_no_ventas_Mattelsa2']\n",
    "df_no_ventas_Mattelsa_2 = df_no_ventas_Mattelsa_2[['ID', \"Titulo\", \"SKU\", \"Vendor\", 'Inventario_Actual', 'Fecha_Creación', 'De_Mattelsa_a_CEDI']]\n",
    "\n",
    "df_no_ventas_Tesoro_2 = new_dfs['df_no_ventas_Tesoro2']\n",
    "df_no_ventas_Tesoro_2 = df_no_ventas_Tesoro_2[['ID', \"Titulo\", \"SKU\", \"Vendor\", 'Inventario_Actual', 'Fecha_Creación', 'De_Tesoro_a_CEDI']]\n",
    "\n",
    "df_no_ventas_Lomas_2 = new_dfs['df_no_ventas_Lomas2']\n",
    "df_no_ventas_Lomas_2 = df_no_ventas_Lomas_2[['ID', \"Titulo\", \"SKU\", \"Vendor\", 'Inventario_Actual', 'Fecha_Creación', 'De_Lomas_a_CEDI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58816c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [presencia_cedi_Tesoro, presencia_cedi_Lomas , presencia_cedi_Matelsa]\n",
    "\n",
    "# Nombres originales de los DataFrames\n",
    "df_names = ['presencia_cedi_Tesoro', 'presencia_cedi_Lomas' , 'presencia_cedi_Matelsa']\n",
    "\n",
    "# Diccionario para almacenar los nuevos DataFrames\n",
    "new_dfs = {}\n",
    "\n",
    "# Crear y guardar un DataFrame \"merged\" para cada uno\n",
    "for i, df in enumerate(dfs):\n",
    "    merged_df = pd.merge(df, inventario_original[['ID', 'Title', 'Variant SKU','Vendor']], on='ID', how='left')\n",
    "    merged_df.rename(columns={'Title': 'Titulo', 'Variant SKU':'SKU'}, inplace=True)\n",
    "    \n",
    "    # Creando el nuevo nombre y asignándolo al diccionario\n",
    "    new_name = df_names[i] +'2'\n",
    "    new_dfs[new_name] = merged_df\n",
    "\n",
    "presencia_cedi_Tesoro_2 = new_dfs['presencia_cedi_Tesoro2']\n",
    "presencia_cedi_Tesoro_2 = presencia_cedi_Tesoro_2[['ID', \"Titulo\", \"SKU\", \"Vendor\", 'De_CEDI_a_Tesoro' ]]\n",
    "\n",
    "presencia_cedi_Lomas_2 = new_dfs['presencia_cedi_Lomas2']\n",
    "presencia_cedi_Lomas_2 = presencia_cedi_Lomas_2[['ID', \"Titulo\", \"SKU\", \"Vendor\", 'De_CEDI_a_Lomas']]\n",
    "\n",
    "presencia_cedi_Matelsa_2 = new_dfs['presencia_cedi_Matelsa2']\n",
    "presencia_cedi_Matelsa_2 = presencia_cedi_Matelsa_2[['ID', \"Titulo\", \"SKU\", \"Vendor\",'De_CEDI_a_Mattelsa' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3ea7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "planeta = pd.read_excel(\"CATALOGO BUKZ PLANETA.xlsx\")\n",
    "penguin = pd.read_excel(\"CATALOGO ACTUALIZADO 26.09.2023 PRH.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para el primer grupo de DataFrames (Lomas):\n",
    "dfs_Lomas = [lomas_final_2, df_no_ventas_Lomas_2, df_distribucion_Lomas, presencia_cedi_Lomas_2]\n",
    "\n",
    "concatenado_Lomas_final = pd.concat([df[['ID', 'SKU']] for df in dfs_Lomas], ignore_index=True)\n",
    "\n",
    "# Para el segundo grupo de DataFrames (Tesoro):\n",
    "dfs_Tesoro = [tesoro_final_2, df_no_ventas_Tesoro_2, df_distribucion_Tesoro, presencia_cedi_Tesoro_2]\n",
    "\n",
    "concatenado_Tesoro_final = pd.concat([df[['ID', 'SKU']] for df in dfs_Tesoro], ignore_index=True)\n",
    "\n",
    "# Para el tercer grupo de DataFrames (Mattelsa):\n",
    "dfs_Mattelsa = [mattelsa_final_2, df_no_ventas_Mattelsa_2, df_distribucion_Mattelsa, presencia_cedi_Matelsa_2]\n",
    "\n",
    "concatenado_Mattelsa_final = pd.concat([df[['ID', 'SKU']] for df in dfs_Mattelsa], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5175b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "planeta['EAN'] = pd.to_numeric(planeta['EAN'], errors='coerce')\n",
    "planeta['EAN'] = planeta['EAN'].astype('Int64')\n",
    "\n",
    "penguin['ISBN'] = pd.to_numeric(penguin['ISBN'], errors='coerce')\n",
    "penguin['ISBN'] = penguin['ISBN'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d2dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin = penguin[(penguin[\"Cantidad ATP (Disponibilidad)\"] > 0)]\n",
    "planeta = planeta[(planeta[\"STOCK\"] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenado_Lomas_final['SKU'] = pd.to_numeric(concatenado_Lomas_final['SKU'], errors='coerce')\n",
    "concatenado_Lomas_final['SKU'] = concatenado_Lomas_final['SKU'].astype('Int64')\n",
    "\n",
    "concatenado_Tesoro_final['SKU'] = pd.to_numeric(concatenado_Tesoro_final['SKU'], errors='coerce')\n",
    "concatenado_Tesoro_final['SKU'] = concatenado_Tesoro_final['SKU'].astype('Int64')\n",
    "\n",
    "concatenado_Mattelsa_final['SKU'] = pd.to_numeric(concatenado_Mattelsa_final['SKU'], errors='coerce')\n",
    "concatenado_Mattelsa_final['SKU'] = concatenado_Mattelsa_final['SKU'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5862e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenados = {\n",
    "    'Lomas': concatenado_Lomas_final,\n",
    "    'Tesoro': concatenado_Tesoro_final,\n",
    "    'Mattelsa': concatenado_Mattelsa_final\n",
    "}\n",
    "\n",
    "# Diccionarios para guardar los DataFrames de EANs e ISBNs no encontrados\n",
    "not_found_planeta = {}\n",
    "not_found_penguin = {}\n",
    "\n",
    "for name, concat_df in concatenados.items():\n",
    "    # Cruzamos con planeta\n",
    "    merged_with_planeta = pd.merge(left=planeta, right=concat_df, left_on='EAN', right_on='SKU', how='left', indicator=True)\n",
    "    not_in_concatenado_planeta = merged_with_planeta[merged_with_planeta['_merge'] == 'left_only']\n",
    "    \n",
    "    # Cruzamos con penguin\n",
    "    merged_with_penguin = pd.merge(left=penguin, right=concat_df, left_on='ISBN', right_on='SKU', how='left', indicator=True)\n",
    "    not_in_concatenado_penguin = merged_with_penguin[merged_with_penguin['_merge'] == 'left_only']\n",
    "    \n",
    "    # Guardamos los DataFrames en los diccionarios usando una clave compuesta por la sede y la editorial\n",
    "    not_found_planeta[f'{name}_planeta'] = not_in_concatenado_planeta\n",
    "    not_found_penguin[f'{name}_penguin'] = not_in_concatenado_penguin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found_in_Lomas_planeta = not_found_planeta['Lomas_planeta']\n",
    "not_found_in_Lomas_penguin = not_found_penguin['Lomas_penguin']\n",
    "\n",
    "not_found_in_Tesoro_planeta = not_found_planeta['Tesoro_planeta']\n",
    "not_found_in_Tesoro_penguin = not_found_penguin['Tesoro_penguin']\n",
    "\n",
    "not_found_in_Mattelsa_planeta = not_found_planeta['Mattelsa_planeta']\n",
    "not_found_in_Mattelsa_penguin = not_found_penguin['Mattelsa_penguin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445822ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eab2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_sugerencias(df_origen, vendor_name):\n",
    "    df_sugerido = df_origen[['EAN', 'TITULO', 'AUTOR', 'SELLO', 'PVP', 'STOCK']].copy()\n",
    "    df_sugerido['sugerido'] = df_sugerido['STOCK'].apply(lambda x: 2 if x > 10 else 1)\n",
    "    df_sugerido[\"Vendor\"] = vendor_name\n",
    "    return df_sugerido[['EAN', 'TITULO', 'AUTOR', 'Vendor', 'SELLO', 'PVP', 'STOCK','sugerido']]\n",
    "\n",
    "sugerido_planeta_Lomas = crear_sugerencias(not_found_in_Lomas_planeta, 'Editorial Planeta')\n",
    "sugerido_planeta_Tesoro = crear_sugerencias(not_found_in_Tesoro_planeta, 'Editorial Planeta')\n",
    "sugerido_planeta_Mattelsa = crear_sugerencias(not_found_in_Mattelsa_planeta, 'Editorial Planeta')\n",
    "\n",
    "dataframes = [sugerido_planeta_Lomas, sugerido_planeta_Tesoro, sugerido_planeta_Mattelsa] \n",
    "\n",
    "for df in dataframes:\n",
    "    df.rename(columns={'EAN':'SKU', 'TITULO':'Titulo', 'AUTOR':'Autor','SELLO':'Editorial', 'sugerido':'Sugerido'}, inplace=True)\n",
    "    df.drop(columns=['STOCK'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_sugerencias(df_origen, vendor_name):\n",
    "    df_sugerido = df_origen[['ISBN', 'Titulo', 'Autor', 'Sello Editorial', 'Cantidad ATP (Disponibilidad)', 'PVP Actual']].copy()\n",
    "    df_sugerido['sugerido'] = df_sugerido['Cantidad ATP (Disponibilidad)'].apply(lambda x: 2 if x > 10 else 1)\n",
    "    df_sugerido[\"Vendor\"] = vendor_name\n",
    "    return df_sugerido[['ISBN', 'Titulo', 'Autor', 'Vendor', 'Sello Editorial', 'Cantidad ATP (Disponibilidad)', 'PVP Actual', 'sugerido']]\n",
    "\n",
    "sugerido_penguin_Lomas = crear_sugerencias(not_found_in_Lomas_penguin, 'Penguin RandomHouse')\n",
    "sugerido_penguin_Tesoro = crear_sugerencias(not_found_in_Tesoro_penguin, 'Penguin RandomHouse')\n",
    "sugerido_penguin_Mattelsa = crear_sugerencias(not_found_in_Mattelsa_penguin, 'Penguin RandomHouse')\n",
    "\n",
    "dataframes = [sugerido_penguin_Lomas, sugerido_penguin_Tesoro, sugerido_penguin_Mattelsa] \n",
    "\n",
    "for df in dataframes:\n",
    "    df.rename(columns={'ISBN':'SKU','Sello Editorial':'Editorial', 'sugerido':'Sugerido', 'PVP Actual':'PVP'}, inplace=True)\n",
    "    df.drop(columns=['Cantidad ATP (Disponibilidad)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7ee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planeta_penguin_Lomas = pd.concat([sugerido_planeta_Lomas, sugerido_penguin_Lomas], ignore_index=True)\n",
    "\n",
    "df_planeta_penguin_Tesoro = pd.concat([sugerido_planeta_Tesoro, sugerido_penguin_Tesoro], ignore_index=True)\n",
    "\n",
    "df_planeta_penguin_Mattelsa = pd.concat([sugerido_planeta_Mattelsa, sugerido_penguin_Mattelsa], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('Sugerido_Lomas_Nov2023.xlsx', engine='openpyxl') as writer:\n",
    "    lomas_final_2.to_excel(writer, sheet_name='Con_Ventas', index=False)\n",
    "    df_no_ventas_Lomas_2.to_excel(writer, sheet_name='No_ventas', index=False)\n",
    "    df_distribucion_Lomas.to_excel(writer, sheet_name='Venta_entre_sedes', index=False)\n",
    "    presencia_cedi_Lomas_2.to_excel(writer, sheet_name='Cedi_Inv', index=False)\n",
    "    df_planeta_penguin_Lomas.to_excel(writer, sheet_name='Planeta_Penguin', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880fe116",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('Sugerido_Tesoro_Nov2023.xlsx', engine='openpyxl') as writer:\n",
    "    tesoro_final_2.to_excel(writer, sheet_name='Con_Ventas', index=False)\n",
    "    df_no_ventas_Tesoro_2.to_excel(writer, sheet_name='No_ventas', index=False)\n",
    "    df_distribucion_Tesoro.to_excel(writer, sheet_name='Venta_entre_sedes', index=False)\n",
    "    presencia_cedi_Tesoro_2.to_excel(writer, sheet_name='Cedi_Inv', index=False)\n",
    "    df_planeta_penguin_Tesoro.to_excel(writer, sheet_name='Planeta_Penguin', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b357fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('Sugerido_Mattelsa_Nov2023.xlsx', engine='openpyxl') as writer:\n",
    "    mattelsa_final_2.to_excel(writer, sheet_name='Con_Ventas', index=False)\n",
    "    df_no_ventas_Mattelsa_2.to_excel(writer, sheet_name='No_ventas', index=False)\n",
    "    df_distribucion_Mattelsa.to_excel(writer, sheet_name='Venta_entre_sedes', index=False)\n",
    "    presencia_cedi_Matelsa_2.to_excel(writer, sheet_name='Cedi_Inv', index=False)\n",
    "    df_planeta_penguin_Mattelsa.to_excel(writer, sheet_name='Planeta_Penguin', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
